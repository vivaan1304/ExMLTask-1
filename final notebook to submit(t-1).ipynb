{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np \nimport os\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T17:40:20.876481Z","iopub.execute_input":"2022-01-12T17:40:20.877037Z","iopub.status.idle":"2022-01-12T17:40:20.881118Z","shell.execute_reply.started":"2022-01-12T17:40:20.877001Z","shell.execute_reply":"2022-01-12T17:40:20.880464Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = \"../input/exml-prelims-task-1/train/train\"\nTEST_DIR = \"../input/exml-prelims-task-1/test/test\"\ntrainImagesList = glob(os.path.join(TRAIN_DIR, \"**/*.png\")) # stores ALL the files in the training dir\ntestImagesList = glob(os.path.join(TEST_DIR, \"*.png\")) # stores ALL the files in the test dir\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T17:40:25.050107Z","iopub.execute_input":"2022-01-12T17:40:25.050645Z","iopub.status.idle":"2022-01-12T17:40:25.723913Z","shell.execute_reply.started":"2022-01-12T17:40:25.050606Z","shell.execute_reply":"2022-01-12T17:40:25.723195Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print('number of training images', len(trainImagesList))\nprint('number of testing images', len(testImagesList))\n# get size of training and test sets","metadata":{"execution":{"iopub.status.busy":"2022-01-12T17:41:16.004515Z","iopub.execute_input":"2022-01-12T17:41:16.005214Z","iopub.status.idle":"2022-01-12T17:41:16.010496Z","shell.execute_reply.started":"2022-01-12T17:41:16.005177Z","shell.execute_reply":"2022-01-12T17:41:16.009676Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# The images are converted from (1600px x 1200px) to (256px x 256px) and the images are converted into grayscale\n# That is images are inputted into the CNN with the input shape (256, 256, 1)\n\n# The CNN has a combination of CONV2D layer and MaxPool2D layer with filter size of (11,11) to extract the\n# important features of the hand which can be done better with a large filter size.\n# It is followed by combinations of CONV2D layer and MaxPool2D layer with filter sizes of (7,7), (5,5) and\n# 3 filter sizes of (3,3).\n\n# Then there is a flatten layer followed by a few dropout and  dense layers with activation function as relu.\n# The dropout layer is added to prevent overfitting of the model to the training data.\n\n# The final layer is a single neuron with activation function as sigmoid\n\n\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (11,11), padding='same', activation='relu', input_shape = (256, 256, 1)),\n    tf.keras.layers.MaxPool2D(2,2),\n    \n    tf.keras.layers.Conv2D(48, (7,7),  activation='relu', padding='same'),\n    tf.keras.layers.MaxPool2D(2,2),\n    \n    tf.keras.layers.Conv2D(64, (5,5), activation='relu', padding='same'),\n    tf.keras.layers.MaxPool2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.MaxPool2D(4,4),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.MaxPool2D(2,2),\n    \n    tf.keras.layers.Conv2D(196, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.MaxPool2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.01),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dropout(0.01),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.summary()\nmodel.compile(loss=\"binary_crossentropy\", metrics = ['acc'], \n              optimizer = tf.keras.optimizers.Adam()) \n\n#I have used the loss as binary_crossentropy as it is a binary classifciation problem.\n#An adam optimizer due to the following reasons:- \n #   1. it combines both the properties AdaGrad RMSProp\n #   2. it is also easy to intialise and auto-adjusts learning rate\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T18:11:27.408305Z","iopub.execute_input":"2022-01-12T18:11:27.408661Z","iopub.status.idle":"2022-01-12T18:11:27.518186Z","shell.execute_reply.started":"2022-01-12T18:11:27.408625Z","shell.execute_reply":"2022-01-12T18:11:27.517478Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Used an ImageDataGenerator which automatically labels images in a directory according to their folder names\ntrain_datagen = ImageDataGenerator(rescale = (1/255)) \ntrain_data = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    target_size = (256,256), # used target size of 256,256 in order to fit a smaller image to the CONVnet\n    color_mode = 'grayscale', # converted the image to grayscale\n    batch_size = 100, \n    class_mode = 'binary' # the classification is binary\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T18:11:34.003329Z","iopub.execute_input":"2022-01-12T18:11:34.004040Z","iopub.status.idle":"2022-01-12T18:11:36.520783Z","shell.execute_reply.started":"2022-01-12T18:11:34.003990Z","shell.execute_reply":"2022-01-12T18:11:36.519852Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# used learning rate decay so that after reaching near a global minimum, our code does not overshoot it.\n# we decrease the learning rate after each epoch by 0.1\nclass LearningRateDecay(tf.keras.callbacks.Callback):\n    def __init__(self, gamma, *args, **kwargs):\n        self.gamma = gamma\n        super().__init__(*args, **kwargs)\n        \n    def on_epoch_end(self, epoch, logs={}):\n        if epoch >=0:\n            lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n            lr *= self.gamma\n            tf.keras.backend.set_value(self.model.optimizer.learning_rate, lr)\n        if logs.get('loss') < 1e-5: # when the loss goes below 1e-5 then we can stop training\n            self.model.stop_training = True\n            print('\\nasasdsadsd')\nmodel.fit(\n    train_data,\n    epochs = 20,\n    verbose=1,\n    callbacks=[LearningRateDecay(0.9)]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T18:15:22.534811Z","iopub.execute_input":"2022-01-12T18:15:22.535068Z","iopub.status.idle":"2022-01-12T18:55:01.390063Z","shell.execute_reply.started":"2022-01-12T18:15:22.535038Z","shell.execute_reply":"2022-01-12T18:55:01.389373Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.save('saved_model/my_model')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:17:49.996134Z","iopub.execute_input":"2022-01-12T19:17:49.996423Z","iopub.status.idle":"2022-01-12T19:17:51.982542Z","shell.execute_reply.started":"2022-01-12T19:17:49.996391Z","shell.execute_reply":"2022-01-12T19:17:51.981798Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# code to write output to csv file\nfrom tqdm import tqdm\nTEST_DIR = \"../input/exml-prelims-task-1/test/test\"\nOUTPUT_FILE= \"./sub2.csv\"\n\n!echo \"id,AspectofHand\" > {OUTPUT_FILE}\n\nfor f in tqdm(os.listdir(TEST_DIR)):\n    img_path = os.path.join(TEST_DIR, f)\n    img = img_to_array(load_img(img_path, grayscale =True, target_size = (256,256))) \n    pred = model.predict(np.expand_dims(img, axis=0))\n    \n    with open(OUTPUT_FILE, \"a\") as file:\n        op_str = f\"{f.split('.')[0]},{int(pred[0,0])}\"\n        file.write(op_str)\n        file.write('\\n')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:25:12.186193Z","iopub.execute_input":"2022-01-12T19:25:12.186458Z","iopub.status.idle":"2022-01-12T19:32:29.479708Z","shell.execute_reply.started":"2022-01-12T19:25:12.186429Z","shell.execute_reply":"2022-01-12T19:32:29.478885Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}